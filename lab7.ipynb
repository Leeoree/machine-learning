{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed27b27-e9fb-4d50-b959-b44a59b94a0a",
   "metadata": {},
   "source": [
    "# Лабораторная работа №7. Решающие деревья. Усиление распознавателей\n",
    "\n",
    "В данной лабораторной работе рассматривается использование бинарных распознающих деревьев и их ансамблей для решения задачи классификации.\n",
    "\n",
    "Распознающим бинарным деревом называется дерево, с каждой вершиной $v$ которого связаны:\n",
    "\n",
    "1. Некоторое подмножество $\\mathcal{X}_v \\subset \\mathcal{X}$;\n",
    "1. Подвыборка $\\mathcal{D}_v \\subset \\mathcal{D}$ обучающей выборки $\\mathcal{D}$, такая, что\n",
    "$$\n",
    "    \\mathcal{D}_v = \\left\\{(\\mathbf{x}, t) \\in \\mathcal{D} \\,\\vert\\, \\mathbf{x} \\in \\mathcal{X}_v\\right\\};\n",
    "$$\n",
    "1. Некоторое правило $f_v: \\mathcal{X} \\to \\{0, 1\\}$, определяющее разбиение множества $\\mathcal{X}$ на $K$ непересекающихся подмножеств.\n",
    "\n",
    "Цель построения дерева решений состоит либо в классификации векторов $\\mathbf{x}$, либо в оценке математического ожидания отклика при данном значении $\\mathbf{x}$.\n",
    "Процесс принятия решения начинается с корневой вершины и состоит в последовательном применении правил, связанных с вершинами дерева.\n",
    "Результатом этого процесса является определение терминальной вершины $v$, такой что $\\mathbf{x} \\in \\mathcal{X}_v$.\n",
    "\n",
    "Распознающие деревья редко применяют в качестве самостоятельного распознавателя, так как хорошего качества распознавания от них редко удается добиться.\n",
    "Вместо этого их широко применяют в качестве «сырья» в методах усиления распознавателей, где синтез решения отдельных классификаторов, составляющих ансамбль, осуществляется путем их голосования.\n",
    "\n",
    "Метод баггинга основан на формировании обучающей выборки для каждого классификатора ансамбля с помощью бутстрепа, то есть случайной выборки с возвращениями из исходной обучающей выборки.\n",
    "\n",
    "Суть метода случайных лесов заключается в том, что для каждого дерева ансамбля на стадии расщепления вершин используется только некоторое подмножество случайно отбираемых признаков.\n",
    "Чаще всего размерность такого подмножества выбирается близкой к $\\sqrt{p}$, где $p$ $-$ размерность всего пространства признаков.\n",
    "\n",
    "Идея метода бустинга состоит в том, что классификаторы ансамбля строятся последовательно, и на каждой итерации происходит коррекция (перевзвешивание) образов обучающей выборки.\n",
    "Коррекция осуществляется таким образом, чтобы соответствующий классификатор дал меньше ошибок на тех образах, на которых часто делали ошибки классификаторы, построенные на предыдущих итерациях алгоритма.\n",
    "Кроме того, каждому классификатору приписывается некоторый вес исходя из количества допущенных им ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863a49f-3310-40c5-973c-0551fcffb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc48cd-20bc-4ffb-9113-1c7206a316ec",
   "metadata": {},
   "source": [
    "## Задание №1\n",
    "\n",
    "Сгенерируйте датасет с 2 признаками размеро 3000 строк (`n_informative=2`, остальные параметры следует установить в 0).\n",
    "В качестве `random_state` используйте свой порядковый номер в списке.\n",
    "Разделите датасет на обучающую и тестовую выборки.\n",
    "Размер тестовой выборки следует выбрать равным 20% от размера всей выборки.\n",
    "Не забывайте про параметр `random_state` для повторяемости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e0fdc-0dd3-4444-bb52-d2945cdccd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sk.datasets.make_classification(???)\n",
    "\n",
    "_, (ax0, ax1) = plt.subplots(1, 2, figsize=(2*5, 4))\n",
    "ax0.scatter\n",
    "ax0.set(??? 'Обучающая выборка')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbfb6c-a61b-41dd-832f-91892d5af0ea",
   "metadata": {},
   "source": [
    "## Задание №2\n",
    "\n",
    "Найдите наилучшие параметры решающего дерева `DecisionTreeClassifier`.\n",
    "Для этого постройте графики зависимостей _accuracy_ от сложности модели (максимального числа разделений) для обучающей и тестовой выборок.\n",
    "После чего выберите оптимальное значение сложности модели.\n",
    "\n",
    "**Замечание.**\n",
    "Оптимальные параметры следует выбирать по наилучшему значению на тестовой выборке.\n",
    "Если в исследуемой зависимости наблюдается несколько пиков с наилучшим значением, то стоит принять в рассмотрение также результат на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee6aff-b6b7-43e1-af76-263806264cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = range(1, 30)\n",
    "criterions = [???]\n",
    "_, axes = plt.subplots(1, len(criterions), figsize=(len(criterions)*5, 4))\n",
    "for criterion, ax in zip(criterions, axes):\n",
    "    metrics_train, metrics_test = [], []\n",
    "    ???\n",
    "\n",
    "    ax.plot(max_depth, metrics_train, label='train')\n",
    "    ax.plot(???)\n",
    "    ax.set(xlabel='max depth', ylabel='accuracy', title='Точность (accuracy) для критерия ' + criterion)\n",
    "    ax.legend()\n",
    "    \n",
    "    print(criterion, ???, 'max_depth:', ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222a799-7f87-425d-a863-a0717f25634a",
   "metadata": {},
   "source": [
    "**Вопросы:**\n",
    "\n",
    "1. Какие критерии были рассмотрены?\n",
    "1. Запишите полученную наилучшую точность и максимальное число разделений для каждого критерия.\n",
    "1. Какой критерий разделения дает наилучший результат?\n",
    "1. Наблюдается ли эффект переобучения (если да, то с чем он связан)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6c40f-2aa8-4b8f-a403-2ad3e9c02523",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8cf8c3-f990-4428-8181-72b97c29586f",
   "metadata": {},
   "source": [
    "Визуализируйте разделение пространства признаков для наилучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e9aca-55e3-46a0-826b-e90143607aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = x_test[:, 0].min() - 1, x_test[:, 0].max() + 1\n",
    "y_min, y_max = x_test[:, 1].min() - 1, x_test[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05), np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "best_model = ???\n",
    "Z = best_model.predict(np.c_[xx.ravel(), yy.ravel(), np.zeros((xx.ravel().shape[0], x_test.shape[1] - 2))])\n",
    "plt.contourf(xx, yy, Z.reshape(xx.shape), cmap=plt.cm.Paired, alpha=0.5)\n",
    "plt.scatter(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed67985-59d5-450e-a438-f0dd3926baea",
   "metadata": {},
   "source": [
    "**Вопросы:**\n",
    "\n",
    "1. Чем характерно отличается полученное разбиение от тех вариантов, что получались в прошлых лабораторных работах?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f401319-7341-42e7-b421-35bd261ff2a0",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e69e84-c0db-4591-a9aa-0c64d39a0577",
   "metadata": {},
   "source": [
    "## Задание №3\n",
    "\n",
    "Найдите наилучшие параметры ансамбля, полученного баггингом `BaggingClassifier`.\n",
    "Для этого воспользуйтесь функцией `GridSearchCV` с указанием кросс-валидации.\n",
    "Рассмотрите такие параметры перебора:\n",
    "\n",
    "* Максимальное число разделений (от 1 до 20)\n",
    "* Максимальное доля обучающей выборки\n",
    "* Количество деревьев в ансамбле (от 1 до 100)\n",
    "\n",
    "Шаг для перебора каждого из параметров можете выбрать самостоятельно.\n",
    "Визуализируйте разделение пространства признаков для наилучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ed8e9-58e3-408e-8943-d9c1ad331cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    'base_estimator__max_depth' : ???,\n",
    "    'max_samples' : ??? np.linspace,\n",
    "    'n_estimators' : ??? np.linspace.astype(int)}\n",
    "\n",
    "gs = sk.model_selection.GridSearchCV(???,\n",
    "                                     param_grid=param_grid, return_train_score=True, n_jobs=-1)\n",
    "???\n",
    "\n",
    "Z = gs.predict(???)\n",
    "???\n",
    "\n",
    "print(gs.best_params_)\n",
    "print('train', gs.score(x_train, y_train))\n",
    "print('test', ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675b855-a036-4941-b529-ce0f4bfcf085",
   "metadata": {},
   "source": [
    "**Вопросы:**\n",
    "\n",
    "1. Удалось ли увеличить качество модели по сравнению с одним распознающим деревом?\n",
    "1. Как и почему изменилась форма разделяющей поверхности?\n",
    "1. Как изменилась оптимальная сложность деревьев по сравнению с предыдущим заданием и с чем это связано?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f702da5-e1f0-4f1e-94b6-f90e240dc1f5",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf36b8-90be-422a-bd11-7bd323f46a95",
   "metadata": {},
   "source": [
    "Проанализируйте зависимости _accuracy_ от конкретных параметров.\n",
    "Для этого используйте информацию из словаря `cv_results_`, беря во внимание полученные оптимальные параметры `best_params_`.\n",
    "Постройте графики зависимости среднего значения _accuracy_ для каждого из параметров, фиксируя остальные параметры в значениях, взятых из `best_params_`.\n",
    "Графики должны быть построены для обучающей и тестовой выборок, также показан разброс на тестовой выбоке (разброс вычисляется благодаря кросс-валидации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02105a3d-ddbb-45ed-9bdc-7a05a9f2664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)\n",
    "\n",
    "_, axes = plt.subplots(1, len(gs.best_params_), figsize=(len(gs.best_params_)*5, 4))\n",
    "for param, ax in zip(gs.best_params_.keys(), axes):\n",
    "    reduced_dict = {k:v for k, v in gs.best_params_.items() if k != param}\n",
    "    idx = [i for i, x in enumerate(gs.cv_results_['params']) if reduced_dict.items() <= x.items()]\n",
    "\n",
    "    x, y, t, s = (gs.cv_results_[???][???] for t in [f'param_{param}', 'mean_train_score', 'mean_test_score', 'std_test_score'])\n",
    "    ax.plot(x, y, label='???')\n",
    "    ax.plot(x, t, label='???')\n",
    "    ax.fill_between(list(x), t - 2 * s, t + 2 * s, facecolor='orange', alpha=.2)\n",
    "    ax.set(xlabel=param, ylabel='accuracy', title='Точность для ' + param)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ebf98-d856-4dc0-a79b-f02c6c00ecb8",
   "metadata": {},
   "source": [
    "**Вопросы:**\n",
    "\n",
    "1. Опишите поведение графиков для каждого из параметров.\n",
    "1. Изменился ли график максимального количества разбиения по сравнению с предыдущим вариантом? Почему?\n",
    "1. Как связаны оптимальная сложность деревьев и количество распознающих деревьев?\n",
    "1. За что отвечает параметр `max_samples`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c02700-6696-4e60-ae90-8a7ef6e5af8b",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ffc07c-944a-44cc-9009-737a7e934162",
   "metadata": {},
   "source": [
    "## Задание №4\n",
    "\n",
    "Подготовьте датасет mnist через функцию `load_digits` для дальнейшей работы.\n",
    "Преобразуйте каждое изображение в одномерный вектор нормированных признаков.\n",
    "Разделите датасет на обучающую и тестовую выборки.\n",
    "Размер тестовой выборки следует выбрать равным 20% от размера всей выборки.\n",
    "Не забудьте указать `random_state` для повторяемости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11109bd9-1eab-4c38-93d5-6498401db0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = ???\n",
    "x_train, x_test, y_train, y_test = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ac8fa-8a85-4ae4-a416-15b3da8826fc",
   "metadata": {},
   "source": [
    "## Задание №5\n",
    "\n",
    "Найдите наилучшие параметры для ансамблей, полученных баггингом, методом адаптивного бустинга, а также случайного леса с помощью `GridSearchCV`.\n",
    "Выведите _accuracy_ для обучающей и тестовой выборок.\n",
    "Параметры переборов:\n",
    "\n",
    "* Макимальная глубина деревьев - от 1 до 20\n",
    "* Количество деревьев - от 10 до 100\n",
    "* `max_samples` и `max_features` - от 0 до 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3879d17-5193-4e27-a2e4-f152401ff4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_prototype = sk.tree.DecisionTreeClassifier(random_state=4)\n",
    "\n",
    "params = {\n",
    "    'BaggingClassifier': {\n",
    "        'proto': sk.ensemble.???(??? random_state=4),\n",
    "        'grid': {\n",
    "            'base_estimator__max_depth': ??? .astype(int),\n",
    "            'n_estimators': ??? .astype(int),\n",
    "            'max_samples': ???}},\n",
    "    'RandomForestClassifier': {\n",
    "        'proto': sk.ensemble.???(random_state=4),\n",
    "        'grid': {\n",
    "            'max_depth': ???,\n",
    "            'n_estimators': ???,\n",
    "            'max_features': ???}},\n",
    "    'AdaBoostClassifier': {\n",
    "        'proto': sk.ensemble.???(??? random_state=4),\n",
    "        'grid': {\n",
    "            'base_estimator__max_depth' : ???,\n",
    "            'n_estimators' : ???}}}\n",
    "\n",
    "for (name, param) in params.items():\n",
    "    gs = sk.model_selection.GridSearchCV(param['proto'], param_grid=param['grid'], n_jobs=-1)\n",
    "    %time gs.fit(x_train, y_train)\n",
    "    print(name, gs.best_params_)\n",
    "    print('train', gs.score(x_train, y_train))\n",
    "    print('test', gs.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb483bbf-7c29-47b5-ad68-c76ff6ee68b1",
   "metadata": {},
   "source": [
    "**Вопросы:**\n",
    "\n",
    "1. Какова оптимальная размерность подмножества случайно отбираемых признаков для случайного леса?\n",
    "1. Какой метод позволил достичь наилучшего результата?\n",
    "1. Что можно сказать о скорости обучения ансамблей?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d7a68-efc5-4923-9d24-7e89d4f0bab3",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ...\n",
    "1. ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
